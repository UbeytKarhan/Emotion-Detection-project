{"cells":[{"cell_type":"markdown","metadata":{"id":"PJPo8IwUvDCs"},"source":["# **Setup**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6680,"status":"ok","timestamp":1623834736568,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"TF6tceinbqKY","outputId":"da243908-71a8-4158-d934-60cba7502d6a"},"outputs":[{"name":"stderr","output_type":"stream","text":["UsageError: Line magic function `%tensorflow_version` not found.\n"]}],"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"ImportError","evalue":"Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ubeyt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ubeyt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\__init__.py:36\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ubeyt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:26\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m self_check\n\u001b[0;32m     23\u001b[0m \u001b[39m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[39m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m self_check\u001b[39m.\u001b[39;49mpreload_check()\n\u001b[0;32m     28\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m   \u001b[39m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[0;32m     32\u001b[0m   \u001b[39m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ubeyt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py:50\u001b[0m, in \u001b[0;36mpreload_check\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m         missing\u001b[39m.\u001b[39mappend(dll_name)\n\u001b[0;32m     49\u001b[0m     \u001b[39mif\u001b[39;00m missing:\n\u001b[1;32m---> 50\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     51\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mCould not find the DLL(s) \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m. TensorFlow requires that these DLLs \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mbe installed in a directory that is named in your \u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39mPATH\u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39menvironment variable. You may install these DLLs by downloading \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m           \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMicrosoft C++ Redistributable for Visual Studio 2015, 2017 and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     55\u001b[0m           \u001b[39m'\u001b[39m\u001b[39m2019\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m for your platform from this URL: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     56\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m           \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(missing))\n\u001b[0;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m   \u001b[39m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[0;32m     60\u001b[0m   \u001b[39m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[0;32m     61\u001b[0m   \u001b[39m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[0;32m     62\u001b[0m   \u001b[39m# SIGILL).\u001b[39;00m\n\u001b[0;32m     63\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_cpu_feature_guard\n","\u001b[1;31mImportError\u001b[0m: Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads"]}],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":348,"status":"ok","timestamp":1623837825671,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"VPlyEm18uWGc"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'mediapipe'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmediapipe\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mglob\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"]}],"source":["import numpy as np\n","import cv2\n","import mediapipe as mp\n","import time\n","import glob\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Dropout, Flatten\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":232,"status":"ok","timestamp":1623834842274,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"d21hj3p6Ib8o","outputId":"30fffe7e-385a-477d-d845-427da794edbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["[WinError 3] Sistem belirtilen yolu bulamıyor: '/content/project'\n","c:\\Users\\UBEYT KARHAN\\Desktop\\emotion_detection\\facial_emotion_recognition\n"]}],"source":["%cd /content/project"]},{"cell_type":"markdown","metadata":{"id":"pa3K5S8eb1XO"},"source":["# **Parameters & Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":220,"status":"ok","timestamp":1623834857084,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"E2wWgnggQOpk"},"outputs":[],"source":["emotions = {\n","    0: ['Angry', (0,0,255), (255,255,255)],\n","    1: ['Disgust', (0,102,0), (255,255,255)],\n","    2: ['Fear', (255,255,153), (0,51,51)],\n","    3: ['Happy', (153,0,153), (255,255,255)],\n","    4: ['Sad', (255,0,0), (255,255,255)],\n","    5: ['Surprise', (0,255,0), (255,255,255)],\n","    6: ['Neutral', (160,160,160), (255,255,255)]\n","}\n","num_classes = len(emotions)\n","input_shape = (48, 48, 1)\n","weights_1 = 'saved_models/vggnet.h5'\n","weights_2 = 'saved_models/vggnet_up.h5'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":332,"status":"ok","timestamp":1623834860705,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"2JaSYECtFIbP"},"outputs":[],"source":["class VGGNet(Sequential):\n","    def __init__(self, input_shape, num_classes, checkpoint_path, lr=1e-3):\n","        super().__init__()\n","        self.add(Rescaling(1./255, input_shape=input_shape))\n","        self.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'))\n","        self.add(BatchNormalization())\n","        self.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(MaxPool2D())\n","        self.add(Dropout(0.5))\n","\n","        self.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(MaxPool2D())\n","        self.add(Dropout(0.4))\n","\n","        self.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(MaxPool2D())\n","        self.add(Dropout(0.5))\n","\n","        self.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same'))\n","        self.add(BatchNormalization())\n","        self.add(MaxPool2D())\n","        self.add(Dropout(0.4))\n","\n","        self.add(Flatten())\n","        \n","        self.add(Dense(1024, activation='relu'))\n","        self.add(Dropout(0.5))\n","        self.add(Dense(256, activation='relu'))\n","\n","        self.add(Dense(num_classes, activation='softmax'))\n","\n","        self.compile(optimizer=Adam(learning_rate=lr),\n","                    loss=categorical_crossentropy,\n","                    metrics=['accuracy'])\n","        \n","        self.checkpoint_path = checkpoint_path"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":865,"status":"ok","timestamp":1623834866947,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"s1N9r5H2iKEt"},"outputs":[],"source":["model_1 = VGGNet(input_shape, num_classes, weights_1)\n","model_1.load_weights(model_1.checkpoint_path)\n","\n","model_2 = VGGNet(input_shape, num_classes, weights_2)\n","model_2.load_weights(model_2.checkpoint_path)"]},{"cell_type":"markdown","metadata":{"id":"tk4W6vYxcdBE"},"source":["# **Inference**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":236,"status":"ok","timestamp":1623834879548,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"O2o4dgiIRTr2"},"outputs":[],"source":["mp_face_detection = mp.solutions.face_detection\n","mp_drawing = mp.solutions.drawing_utils\n","face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":387,"status":"ok","timestamp":1623836538326,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"QxxLhqRwz0__"},"outputs":[],"source":["def detection_preprocessing(image, h_max=360):\n","    h, w, _ = image.shape\n","    if h > h_max:\n","        ratio = h_max / h\n","        w_ = int(w * ratio)\n","        image = cv2.resize(image, (w_,h_max))\n","    return image\n","\n","def resize_face(face):\n","    x = tf.expand_dims(tf.convert_to_tensor(face), axis=2)\n","    return tf.image.resize(x, (48,48))\n","\n","def recognition_preprocessing(faces):\n","    x = tf.convert_to_tensor([resize_face(f) for f in faces])\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":351,"status":"ok","timestamp":1623836738256,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"VT9FGSGDz2hr"},"outputs":[],"source":["def inference(image):\n","    H, W, _ = image.shape\n","    \n","    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    results = face_detection.process(rgb_image)\n","\n","    if results.detections:\n","        faces = []\n","        pos = []\n","        for detection in results.detections:\n","            box = detection.location_data.relative_bounding_box\n","            # mp_drawing.draw_detection(image, detection)\n","\n","            x = int(box.xmin * W)\n","            y = int(box.ymin * H)\n","            w = int(box.width * W)\n","            h = int(box.height * H)\n","\n","            x1 = max(0, x)\n","            y1 = max(0, y)\n","            x2 = min(x + w, W)\n","            y2 = min(y + h, H)\n","\n","            face = image[y1:y2,x1:x2]\n","            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n","            faces.append(face)\n","            pos.append((x1, y1, x2, y2))\n","    \n","        x = recognition_preprocessing(faces)\n","\n","        y_1 = model_1.predict(x)\n","        y_2 = model_2.predict(x)\n","        l = np.argmax(y_1+y_2, axis=1)\n","\n","        for i in range(len(faces)):\n","            cv2.rectangle(image, (pos[i][0],pos[i][1]),\n","                            (pos[i][2],pos[i][3]), emotions[l[i]][1], 2, lineType=cv2.LINE_AA)\n","            \n","            cv2.rectangle(image, (pos[i][0],pos[i][1]-20),\n","                            (pos[i][2]+20,pos[i][1]), emotions[l[i]][1], -1, lineType=cv2.LINE_AA)\n","            \n","            cv2.putText(image, f'{emotions[l[i]][0]}', (pos[i][0],pos[i][1]-5),\n","                            0, 0.6, emotions[l[i]][2], 2, lineType=cv2.LINE_AA)\n","    \n","    return image"]},{"cell_type":"markdown","metadata":{"id":"4s63kjt6ns27"},"source":["## **Image**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":234,"status":"ok","timestamp":1623838012770,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"eBQbEKs5PChi"},"outputs":[],"source":["def infer_single_image(path):\n","    image = cv2.imread(path)\n","    image = detection_preprocessing(image)\n","    result = inference(image)\n","    cv2.imwrite('run/inference/out.jpg', result)\n","\n","def infer_multi_images(paths):\n","    for i, path in enumerate(paths):\n","        image = cv2.imread(path)\n","        image = detection_preprocessing(image)\n","        result = inference(image)\n","        cv2.imwrite('run/inference/out_'+str(i)+'.jpg', result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQCewyQSQf0p"},"outputs":[],"source":["import cv2\n","\n","\n","# define a video capture object\n","vid = cv2.VideoCapture(0)\n","\n","while(True):\n","\n","    # Capture the video frame\n","    # by frame\n","    ret, frame = vid.read()\n","\n","    image = detection_preprocessing(frame)\n","    result = inference(image)\n","\n","    # Display the resulting frame\n","    cv2.imshow('frame', result)\n","\n","    # the 'q' button is set as the\n","    # quitting button you may use any\n","    # desired button of your choice\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phifpnshRw46"},"outputs":[{"ename":"NameError","evalue":"name 'cv2_imshow' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m out_paths:\n\u001b[0;32m      5\u001b[0m     image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(path)\n\u001b[1;32m----> 6\u001b[0m     cv2_imshow(image)\n","\u001b[1;31mNameError\u001b[0m: name 'cv2_imshow' is not defined"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["paths = np.sort(np.array(glob.glob('images/*.jpg')))\n","infer_multi_images(paths)\n","out_paths = np.sort(np.array(glob.glob('run/inference/*.jpg')))\n","for path in out_paths:\n","    image = cv2.imread(path)\n","    cv2_imshow(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J4vs6enCV97x"},"outputs":[{"name":"stderr","output_type":"stream","text":["UsageError: Line magic function `%cp` not found.\n"]}],"source":["%cp -av /content/project/run/inference/ /content/gdrive/MyDrive/loopQ/project/run/"]},{"cell_type":"markdown","metadata":{"id":"hRE0GhXpbUkM"},"source":["## **Video**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":336,"status":"ok","timestamp":1623833509820,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"ekc0JiaQbT07"},"outputs":[{"ename":"NameError","evalue":"name 'cv2' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m video \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest_video/emotions.mp4\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(video)\n\u001b[0;32m      3\u001b[0m frame_width \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(cap\u001b[39m.\u001b[39mget(\u001b[39m3\u001b[39m))\n\u001b[0;32m      4\u001b[0m frame_height \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(cap\u001b[39m.\u001b[39mget(\u001b[39m4\u001b[39m))\n","\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"]}],"source":["video = 'test_video/emotions.mp4'\n","cap = cv2.VideoCapture(video)\n","frame_width = int(cap.get(3))\n","frame_height = int(cap.get(4))\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","target_h = 360\n","target_w = int(target_h * frame_width / frame_height)\n","out = cv2.VideoWriter('run/out.avi',cv2.VideoWriter_fourcc('M','J','P','G'),\n","                      fps, (target_w,target_h))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":73186,"status":"ok","timestamp":1623833588636,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"Jcd5sst2iGp2"},"outputs":[],"source":["while True:\n","    success, image = cap.read()\n","    if success:\n","        image = resize_image(image)\n","        result = inference(image)\n","        out.write(result)\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","    else:\n","        break\n","    \n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"JJ8Xi3ETpYkX"},"source":["# **Cam**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1623838698628,"user":{"displayName":"Jianming Han","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggzk6L5tAZ5Gi8DaqgCsqP9WRLwiNEdgvr209DkQA=s64","userId":"00040175033446167208"},"user_tz":-120},"id":"Cxp9-2bRiaGg"},"outputs":[],"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def take_photo(filename='cap/photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)\n","  return filename"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"em_EXSUnieJe"},"outputs":[],"source":["filename = take_photo()\n","image = cv2.imread(filename)\n","result = inference(image)\n","cv2_imshow(result)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"inference.ipynb","provenance":[{"file_id":"1dV-sPmPSOyCRsKqGRs7CK8V4h22ht42m","timestamp":1623601457273},{"file_id":"1muoOaBA21nwc1MUlwEDcVyqAuoa5_AYu","timestamp":1623599622276}]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"}}},"nbformat":4,"nbformat_minor":0}
